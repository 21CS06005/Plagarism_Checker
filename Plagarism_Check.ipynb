{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plagarism_Check",
      "provenance": [],
      "collapsed_sections": [
        "JpzF-crDPVbq",
        "zP3g8ylAsLe_",
        "7RtLV3On5mnJ",
        "xSY-gxTaKUEK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting up the environment**"
      ],
      "metadata": {
        "id": "JpzF-crDPVbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnmdrVQ9Mzpr",
        "outputId": "76956092-30c6-4c85-a762-bb99820b401d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Plagarism_Checker' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/21CS06005/Plagarism_Checker.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing and Downloading libraries**"
      ],
      "metadata": {
        "id": "zP3g8ylAsLe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import nltk\n",
        "import string\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import nltk\n",
        "# Download the libraries on the go \n",
        "# - Required for some functions used in this program\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "6CB5Y0btPHZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774293a8-d912-4835-cd0b-067d7f579169"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Functions**"
      ],
      "metadata": {
        "id": "7RtLV3On5mnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readFile(bFileName, tFileName):\n",
        "  basePath = 'Plagarism_Checker/'\n",
        "  try:\n",
        "    f=open(basePath + bFileName,\"r\")\n",
        "    btext =f.read()\n",
        "  except UnicodeDecodeError:\n",
        "    reload(sys)\n",
        "    sys.setdefaultencoding('utf-8')\n",
        "\n",
        "  # Reading the text file to be compared\n",
        "  try:\n",
        "    f=open(basePath + tFileName,\"r\")\n",
        "    ttext =f.read()\n",
        "  except UnicodeDecodeError:\n",
        "    reload(sys)\n",
        "    sys.setdefaultencoding('utf-8')\n",
        "  return [btext, ttext]\n",
        "\n",
        "def performPreProcess(text):\n",
        "  # converting to lower case \n",
        "  text = text.lower()\n",
        "\n",
        "  # Tokenizing the file into words\n",
        "  sent_tokenize_list = sent_tokenize(text)\n",
        "  words=word_tokenize(text)\n",
        "\n",
        "  # Stopwords like articles, prepositions, pronouns, conjunctions, etc \n",
        "  # for English language\n",
        "  stop_words = str(stopwords.words('english'))\n",
        "  noStopwordText=stop_words.replace(\"u'\", \"\")\n",
        "  \n",
        "  # Finding out the words that are not stop-words\n",
        "  res = []\n",
        "  for item in words:\n",
        "      if item not in noStopwordText:\n",
        "          res.append(item)\n",
        "\n",
        "  # Replacing all punctuations from the file with space\n",
        "  repstr=\" \" * 32\n",
        "  table=str.maketrans(string.punctuation,repstr)\n",
        "  mappingTable = str(res).translate(table)\n",
        "\n",
        "  # Grouping various froms of words together\n",
        "  # like - rocks & rock are grouped together\n",
        "  lemmatizedWords=word_tokenize(WordNetLemmatizer().lemmatize(mappingTable))\n",
        "  \n",
        "  # Using porterStemmer library to stem the words\n",
        "  porterStemmer = PorterStemmer()\n",
        "  list1=[]\n",
        "  for word in lemmatizedWords:\n",
        "      k=(porterStemmer.stem(word))\n",
        "      list1.append(k)\n",
        "  return str('  '.join(list1))\n",
        "\n",
        "def displayStats(commonWords, ngbtext):\n",
        "  print (\"\\n  Common Words are - \",commonWords)\n",
        "  print (\"\\n  Length of common words = \",len(commonWords))\n",
        "  print (\"\\n  Ref file after processing is \",len(ngbtext))\n",
        "  print (\"\\n  Pecentage of Similarity\",(len(commonWords)/len(ngbtext))*100)"
      ],
      "metadata": {
        "id": "t1dRIoiJvwGO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check for Plagarism** "
      ],
      "metadata": {
        "id": "xSY-gxTaKUEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkSimilarity(bFileName, tFileName):\n",
        "  # Reading both the files\n",
        "  btext,ttext = readFile(bFileName, tFileName)\n",
        "\n",
        "  print('The base file content is as below: \\n'+btext)\n",
        "  print('\\n\\nThe file content to be checked for similarity is as below: \\n'+ttext)\n",
        "        \n",
        "  preProcessedbtext=performPreProcess(btext)\n",
        "  preProcessedttext=performPreProcess(ttext)\n",
        "  \n",
        "  ngbtext = list(ngrams(preProcessedbtext.split(), 4))\n",
        "  ngttext = list(ngrams(preProcessedttext.split(), 4))\n",
        "\n",
        "  commonWords=[]\n",
        "  for nggram in ngbtext:\n",
        "      if nggram in ngttext:\n",
        "          commonWords.append(nggram)\n",
        "\n",
        "  displayStats(commonWords, ngbtext)"
      ],
      "metadata": {
        "id": "Lw8j_NOhKY8h"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ],
      "metadata": {
        "id": "7oWpe_Lb8zyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseFileName = input(\"Enter the filename: (eg- basefile.txt)\")\n",
        "textFileName = input(\"Enter the filename: (eg- 1.txt)\")\n",
        "checkSimilarity(baseFileName, textFileName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "dvEUDf_586l9",
        "outputId": "3a90119c-52df-483b-ad1b-05cab10c0c87"
      },
      "execution_count": 57,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the filename: (eg- basefile.txt)basefile.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-2364eafc2120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbaseFileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the filename: (eg- basefile.txt)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextFileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the filename: (eg- 1.txt)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcheckSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseFileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextFileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}